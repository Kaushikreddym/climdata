{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to climdata","text":"<p>This project automates the fetching and extraction of weather data from multiple sources \u2014 such as MSWX, DWD HYRAS, ERA5-Land, NASA-NEX-GDDP, and more \u2014 for a given location and time range.</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://Kaushikreddym.github.io/climdata</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>TODO</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"climdata/","title":"climdata module","text":""},{"location":"climdata/#climdata","title":"<code>climdata</code>  <code>special</code>","text":"<p>Top-level package for climdata.</p>"},{"location":"climdata/#climdata.utils","title":"<code>utils</code>  <code>special</code>","text":""},{"location":"climdata/#climdata.utils.config","title":"<code>config</code>","text":""},{"location":"climdata/#climdata.utils.config.load_config","title":"<code>load_config(config_name='config', overrides=None, verbose=False)</code>","text":"<p>Load Hydra config using ./conf in cwd.</p> Source code in <code>climdata/utils/config.py</code> <pre><code>def load_config(config_name=\"config\", overrides=None, verbose=False):\n    \"\"\"\n    Load Hydra config using ./conf in cwd.\n    \"\"\"\n    config_path = _ensure_local_conf()\n    # import ipdb; ipdb.set_trace()\n    with initialize(config_path=config_path, version_base=None):\n        cfg = compose(config_name=config_name, overrides=overrides or [])\n        if verbose:\n            print(OmegaConf.to_yaml(cfg))\n        return cfg\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download","title":"<code>utils_download</code>","text":""},{"location":"climdata/#climdata.utils.utils_download.build_output_filename","title":"<code>build_output_filename(cfg)</code>","text":"<p>Generate full output file path from pattern and config.</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def build_output_filename(cfg: DictConfig) -&gt; str:\n    \"\"\"Generate full output file path from pattern and config.\"\"\"\n    provider = cfg.dataset.lower()\n    parameter = cfg.weather.parameter\n    lat = cfg.location.lat\n    lon = cfg.location.lon\n    start = cfg.time_range.start_date\n    end = cfg.time_range.end_date\n\n    pattern = cfg.output.get(\"filename\", \"{provider}_{parameter}_{start}_{end}.csv\")\n    filename = pattern.format(\n        provider=provider,\n        parameter=parameter,\n        lat=lat,\n        lon=lon,\n        start=start,\n        end=end\n    )\n\n    out_dir = cfg.output.out_dir\n    fmt = cfg.output.fmt  # format is a reserved word in Python, so use 'fmt'\n\n    # return os.path.join(out_dir, fmt, filename)\n    return filename\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download.download_drive_file","title":"<code>download_drive_file(file_id, local_path, service)</code>","text":"<p>Download a single file from Drive to a local path.</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def download_drive_file(file_id, local_path, service):\n    \"\"\"\n    Download a single file from Drive to a local path.\n    \"\"\"\n    request = service.files().get_media(fileId=file_id)\n    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n\n    with io.FileIO(local_path, 'wb') as fh:\n        downloader = MediaIoBaseDownload(fh, request)\n\n        done = False\n        while not done:\n            status, done = downloader.next_chunk()\n            print(f\"   \u2192 Download {int(status.progress() * 100)}% complete\")\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download.fetch_dwd","title":"<code>fetch_dwd(var_cfg)</code>","text":"<p>Download HYRAS data for one variable and a list of years.</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def fetch_dwd(var_cfg):\n    \"\"\"Download HYRAS data for one variable and a list of years.\"\"\"\n    param_mapping = var_cfg.mappings\n    provider = var_cfg.dataset.lower()\n    parameter_key = var_cfg.weather.parameter\n    # Validate provider and parameter\n\n    param_info = param_mapping[provider]['variables'][parameter_key]\n    base_url = param_info[\"base_url\"]\n    prefix = param_info[\"prefix\"]\n    version = param_info[\"version\"]\n\n    start_date = var_cfg.time_range.start_date\n    end_date = var_cfg.time_range.end_date\n\n    # Parse dates &amp; extract unique years\n    start_year = datetime.fromisoformat(start_date).year\n    end_year = datetime.fromisoformat(end_date).year\n    years = list(range(start_year, end_year + 1))\n\n    # output_file = cfg.output.filename\n    os.makedirs(parameter_key, exist_ok=True)\n\n    for year in years:\n        file_name = f\"{prefix}_{year}_{version}_de.nc\"\n        file_url = f\"{base_url}{file_name}\"\n        local_path = os.path.join(var_cfg.data_dir,provider,parameter_key.upper(), file_name)\n        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n        print(f\"\u2b07\ufe0f  Checking: {file_url}\")\n\n        # Check if file exists on server first (HEAD request)\n        head = requests.head(file_url)\n        if head.status_code != 200:\n            raise FileNotFoundError(f\"\u274c Not found on server: {file_url} (HTTP {head.status_code})\")\n\n        if os.path.exists(local_path):\n            print(f\"\u2714\ufe0f  Exists locally: {local_path}\")\n            continue\n\n        print(f\"\u2b07\ufe0f  Downloading: {file_url}\")\n        try:\n            response = requests.get(file_url, stream=True)\n            response.raise_for_status()\n            with open(local_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n            print(f\"\u2705 Saved: {local_path}\")\n        except requests.HTTPError as e:\n            raise RuntimeError(f\"\u274c Failed download: {file_url} \u2014 {e}\")\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download.find_nearest_xy","title":"<code>find_nearest_xy(ds, target_lat, target_lon)</code>","text":"<p>Given a dataset with curvilinear grid, find the nearest x,y index.</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def find_nearest_xy(ds, target_lat, target_lon):\n    \"\"\"\n    Given a dataset with curvilinear grid, find the nearest x,y index.\n    \"\"\"\n    lat = ds['lat'].values  # shape (y,x) or (x,y)\n    lon = ds['lon'].values\n\n    # Flatten to 1D for k-d tree\n    lat_flat = lat.flatten()\n    lon_flat = lon.flatten()\n\n    tree = cKDTree(np.column_stack((lat_flat, lon_flat)))\n    _, idx = tree.query([target_lat, target_lon])\n    iy, ix = np.unravel_index(idx, lat.shape)\n\n    return iy, ix\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download.list_drive_files","title":"<code>list_drive_files(folder_id, service)</code>","text":"<p>List all files in a Google Drive folder, handling pagination.</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def list_drive_files(folder_id, service):\n    \"\"\"\n    List all files in a Google Drive folder, handling pagination.\n    \"\"\"\n    files = []\n    page_token = None\n\n    while True:\n        results = service.files().list(\n            q=f\"'{folder_id}' in parents and trashed = false\",\n            fields=\"files(id, name), nextPageToken\",\n            pageToken=page_token\n        ).execute()\n\n        files.extend(results.get(\"files\", []))\n        page_token = results.get(\"nextPageToken\", None)\n\n        if not page_token:\n            break\n\n    return files\n</code></pre>"},{"location":"common/","title":"Common Concepts in climdata","text":"<p>This page describes common terminology, configuration patterns, and reusable components in the <code>climdata</code> package.</p>"},{"location":"common/#configuration-files","title":"Configuration Files","text":"<ul> <li>All configuration is managed via Hydra and YAML files in the <code>conf/</code> directory.</li> <li>See <code>config.yaml</code> for the main entry point.</li> </ul>"},{"location":"common/#standard-variable-names","title":"Standard Variable Names","text":"<ul> <li>Variables follow CF conventions (see <code>variables.yaml</code>).</li> <li>Example: <code>tas</code> for air temperature, <code>pr</code> for precipitation.</li> </ul>"},{"location":"common/#output-schema","title":"Output Schema","text":"<p>All outputs are standardized to the following columns:</p> Column Description latitude Latitude of observation/grid longitude Longitude of observation/grid time Timestamp source Data source/provider variable Variable name value Observed or modeled value units Units of measurement"},{"location":"common/#regions-and-bounds","title":"Regions and Bounds","text":"<ul> <li>Regions are defined in <code>config.yaml</code> under <code>bounds</code>.</li> <li>Example: <code>europe</code>, <code>global</code>.</li> </ul>"},{"location":"common/#usage-patterns","title":"Usage Patterns","text":"<ul> <li>Use <code>climdata.load_config()</code> to load configuration.</li> <li>Use <code>climdata.DWD(cfg)</code> or <code>climdata.MSWX(cfg)</code> for dataset access.</li> </ul> <p>Add more shared concepts as your documentation grows.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/Kaushikreddym/climdata/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>climdata could always use more documentation, whether as part of the official climdata docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/Kaushikreddym/climdata/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up climdata for local development.</p> <ol> <li> <p>Fork the climdata repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/climdata.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv climdata\n$ cd climdata/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 climdata tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/Kaushikreddym/climdata/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install climdata, run this command in your terminal:</p> <pre><code>pip install climdata\n</code></pre> <p>This is the preferred method to install climdata, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install climdata from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/Kaushikreddym/climdata\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use climdata in a project:</p> <pre><code>import climdata\n</code></pre>"},{"location":"examples/run_downloader/","title":"Downloader Notebook","text":"In\u00a0[\u00a0]: Copied! <pre># !git clone https://github.com/Kaushikreddym/climdata.git\n# %cd climdata\n# !pip install -e .\n\n#import climdata as cd\n# print(\"package successfully installed!\")\n</pre> # !git clone https://github.com/Kaushikreddym/climdata.git # %cd climdata # !pip install -e .  #import climdata as cd # print(\"package successfully installed!\") In\u00a0[\u00a0]: Copied! <pre># \ud83d\udce6 Imports\nimport os\nimport pandas as pd\nfrom omegaconf import OmegaConf\nfrom datetime import datetime\nfrom hydra import initialize, compose\nfrom climdata.utils.utils_download import (\n    fetch_MSWX, fetch_dwd, fetch_dwd_loc,\n    fetch_ee_loc, fetch_ee_loc_mod,\n    extract_ts_MSWX, extract_ts_dwd,\n    build_output_filename\n)\n</pre> # \ud83d\udce6 Imports import os import pandas as pd from omegaconf import OmegaConf from datetime import datetime from hydra import initialize, compose from climdata.utils.utils_download import (     fetch_MSWX, fetch_dwd, fetch_dwd_loc,     fetch_ee_loc, fetch_ee_loc_mod,     extract_ts_MSWX, extract_ts_dwd,     build_output_filename )  In\u00a0[3]: Copied! <pre># \ud83d\udd27 Initialize Hydra and load config with overrides\noverrides = [\n    \"dataset=mswx\",                    # other options: dwd, dwd_hyras, gddp, era5-land\n    \"weather.parameter=pr\",\n    \"time_range.start_date=2014-01-01\",\n    \"time_range.end_date=2014-01-04\",\n    \"location.lat=48.1351\",\n    \"location.lon=11.5761\",\n    \"output.out_dir=./data\"\n]\n\nwith initialize(config_path=\"climdata/conf\", version_base=\"1.3\"):\n    cfg = compose(config_name=\"config\", overrides=overrides)\n\n# \ud83d\udca1 View resolved config\n# OmegaConf.to_container(cfg, resolve=True)\n</pre> # \ud83d\udd27 Initialize Hydra and load config with overrides overrides = [     \"dataset=mswx\",                    # other options: dwd, dwd_hyras, gddp, era5-land     \"weather.parameter=pr\",     \"time_range.start_date=2014-01-01\",     \"time_range.end_date=2014-01-04\",     \"location.lat=48.1351\",     \"location.lon=11.5761\",     \"output.out_dir=./data\" ]  with initialize(config_path=\"climdata/conf\", version_base=\"1.3\"):     cfg = compose(config_name=\"config\", overrides=overrides)  # \ud83d\udca1 View resolved config # OmegaConf.to_container(cfg, resolve=True)  <pre>\n---------------------------------------------------------------------------\nMissingConfigException                    Traceback (most recent call last)\nCell In[3], line 13\n      2 overrides = [\n      3     \"dataset=mswx\",                    # other options: dwd, dwd_hyras, gddp, era5-land\n      4     \"weather.parameter=pr\",\n   (...)\n      9     \"output.out_dir=./data\"\n     10 ]\n     12 with initialize(config_path=\"climdata/conf\", version_base=\"1.3\"):\n---&gt; 13     cfg = compose(config_name=\"config\", overrides=overrides)\n     15 # \ud83d\udca1 View resolved config\n     16 # OmegaConf.to_container(cfg, resolve=True)\n\nFile ~/miniforge3/envs/sdba/lib/python3.10/site-packages/hydra/compose.py:38, in compose(config_name, overrides, return_hydra_config, strict)\n     36 gh = GlobalHydra.instance()\n     37 assert gh.hydra is not None\n---&gt; 38 cfg = gh.hydra.compose_config(\n     39     config_name=config_name,\n     40     overrides=overrides,\n     41     run_mode=RunMode.RUN,\n     42     from_shell=False,\n     43     with_log_configuration=False,\n     44 )\n     45 assert isinstance(cfg, DictConfig)\n     47 if not return_hydra_config:\n\nFile ~/miniforge3/envs/sdba/lib/python3.10/site-packages/hydra/_internal/hydra.py:594, in Hydra.compose_config(self, config_name, overrides, run_mode, with_log_configuration, from_shell, validate_sweep_overrides)\n    576 def compose_config(\n    577     self,\n    578     config_name: Optional[str],\n   (...)\n    583     validate_sweep_overrides: bool = True,\n    584 ) -&gt; DictConfig:\n    585     \"\"\"\n    586     :param config_name:\n    587     :param overrides:\n   (...)\n    591     :return:\n    592     \"\"\"\n--&gt; 594     cfg = self.config_loader.load_configuration(\n    595         config_name=config_name,\n    596         overrides=overrides,\n    597         run_mode=run_mode,\n    598         from_shell=from_shell,\n    599         validate_sweep_overrides=validate_sweep_overrides,\n    600     )\n    601     if with_log_configuration:\n    602         configure_log(cfg.hydra.hydra_logging, cfg.hydra.verbose)\n\nFile ~/miniforge3/envs/sdba/lib/python3.10/site-packages/hydra/_internal/config_loader_impl.py:142, in ConfigLoaderImpl.load_configuration(self, config_name, overrides, run_mode, from_shell, validate_sweep_overrides)\n    133 def load_configuration(\n    134     self,\n    135     config_name: Optional[str],\n   (...)\n    139     validate_sweep_overrides: bool = True,\n    140 ) -&gt; DictConfig:\n    141     try:\n--&gt; 142         return self._load_configuration_impl(\n    143             config_name=config_name,\n    144             overrides=overrides,\n    145             run_mode=run_mode,\n    146             from_shell=from_shell,\n    147             validate_sweep_overrides=validate_sweep_overrides,\n    148         )\n    149     except OmegaConfBaseException as e:\n    150         raise ConfigCompositionException().with_traceback(sys.exc_info()[2]) from e\n\nFile ~/miniforge3/envs/sdba/lib/python3.10/site-packages/hydra/_internal/config_loader_impl.py:243, in ConfigLoaderImpl._load_configuration_impl(self, config_name, overrides, run_mode, from_shell, validate_sweep_overrides)\n    233 def _load_configuration_impl(\n    234     self,\n    235     config_name: Optional[str],\n   (...)\n    239     validate_sweep_overrides: bool = True,\n    240 ) -&gt; DictConfig:\n    241     from hydra import __version__, version\n--&gt; 243     self.ensure_main_config_source_available()\n    244     parsed_overrides, caching_repo = self._parse_overrides_and_create_caching_repo(\n    245         config_name, overrides\n    246     )\n    248     if validate_sweep_overrides:\n\nFile ~/miniforge3/envs/sdba/lib/python3.10/site-packages/hydra/_internal/config_loader_impl.py:129, in ConfigLoaderImpl.ensure_main_config_source_available(self)\n    123 else:\n    124     msg = (\n    125         \"Primary config directory not found.\\nCheck that the\"\n    126         f\" config directory '{source.path}' exists and readable\"\n    127     )\n--&gt; 129 self._missing_config_error(\n    130     config_name=None, msg=msg, with_search_path=False\n    131 )\n\nFile ~/miniforge3/envs/sdba/lib/python3.10/site-packages/hydra/_internal/config_loader_impl.py:102, in ConfigLoaderImpl._missing_config_error(self, config_name, msg, with_search_path)\n     99     else:\n    100         return msg\n--&gt; 102 raise MissingConfigException(\n    103     missing_cfg_file=config_name, message=add_search_path()\n    104 )\n\nMissingConfigException: Primary config directory not found.\nCheck that the config directory '/beegfs/muduchuru/pkgs_fnl/climdata/docs/examples/climdata/conf' exists and readable</pre> In\u00a0[63]: Copied! <pre># \ud83d\udcc1 Generate output filename\ncfg.output.filename = build_output_filename(cfg)\noutput_path = os.path.join(cfg.output.out_dir, cfg.output.filename)\n\nprint(\"\ud83d\udcc1 Output file will be:\", output_path)\n</pre> # \ud83d\udcc1 Generate output filename cfg.output.filename = build_output_filename(cfg) output_path = os.path.join(cfg.output.out_dir, cfg.output.filename)  print(\"\ud83d\udcc1 Output file will be:\", output_path)  <pre>\ud83d\udcc1 Output file will be: ./data/mswx_pr_LAT48.1351_LON11.5761_2014-01-01_2014-01-04.csv\n</pre> In\u00a0[64]: Copied! <pre># \ud83d\ude80 Fetch + extract time series\nprovider = cfg.dataset.lower()\n\nif provider == \"mswx\":\n    fetch_MSWX(cfg)\n    df_out = extract_ts_MSWX(cfg)\nelif provider == \"dwd_hyras\":\n    fetch_dwd(cfg)\n    df_out = extract_ts_dwd(cfg)\nelif provider == \"dwd\":\n    df_out = fetch_dwd_loc(cfg)\nelif provider == \"gddp\":\n    df_out = fetch_ee_loc(cfg)\nelif provider == \"era5-land\":\n    df_out = fetch_ee_loc_mod(cfg)\nelse:\n    raise NotImplementedError(f\"Provider '{provider}' is not supported.\")\n</pre> # \ud83d\ude80 Fetch + extract time series provider = cfg.dataset.lower()  if provider == \"mswx\":     fetch_MSWX(cfg)     df_out = extract_ts_MSWX(cfg) elif provider == \"dwd_hyras\":     fetch_dwd(cfg)     df_out = extract_ts_dwd(cfg) elif provider == \"dwd\":     df_out = fetch_dwd_loc(cfg) elif provider == \"gddp\":     df_out = fetch_ee_loc(cfg) elif provider == \"era5-land\":     df_out = fetch_ee_loc_mod(cfg) else:     raise NotImplementedError(f\"Provider '{provider}' is not supported.\")  <pre>\u2705 All 4 files already exist locally. No download needed.\n\ud83d\udcc2 Opening: ./data/mswx/pr/2014001.nc\n\ud83d\udcc2 Opening: ./data/mswx/pr/2014002.nc\n\ud83d\udcc2 Opening: ./data/mswx/pr/2014003.nc\n\ud83d\udcc2 Opening: ./data/mswx/pr/2014004.nc\n\u2705 Saved MSWX time series to: /beegfs/muduchuru/codes/python/download/data/mswx_pr_LAT48.1351_LON11.5761_2014-01-01_2014-01-04.csv\n</pre> In\u00a0[\u00a0]: Copied! <pre>import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom hydra import initialize, compose\nfrom omegaconf import OmegaConf\n\nfrom utils.utils_download import (\n    fetch_MSWX, extract_ts_MSWX,\n    fetch_dwd, extract_ts_dwd,\n    fetch_dwd_loc, fetch_ee_loc, fetch_ee_loc_mod,\n    build_output_filename\n)\n\n\ndatasets = [\"mswx\", \"dwd_hyras\", \"dwd\", \"gddp\", \"era5-land\"]\nparameter = \"tasmax\"\n\noverrides_base = [\n    f\"weather.parameter={parameter}\",\n    \"time_range.start_date=2014-01-01\",\n    \"time_range.end_date=2014-12-31\",\n    \"location.lat=48.1351\",\n    \"location.lon=11.5761\"\n]\n\ndf_all = []\n\nwith initialize(config_path=\"conf\", version_base=\"1.3\"):\n    for ds in datasets:\n        print(f\"\ud83d\udd04 Processing: {ds}\")\n        overrides = [f\"dataset={ds}\"] + overrides_base\n        cfg = compose(config_name=\"config\", overrides=overrides)\n        # \ud83d\udcc1 Generate output filename\n        cfg.output.filename = build_output_filename(cfg)\n        output_path = os.path.join(cfg.output.out_dir, cfg.output.filename)\n\n        print(\"\ud83d\udcc1 Output file will be:\", output_path)\n\n        try:\n            if ds == \"mswx\":\n                fetch_MSWX(cfg)\n                df_out = extract_ts_MSWX(cfg)\n            elif ds == \"dwd_hyras\":\n                fetch_dwd(cfg)\n                df_out = extract_ts_dwd(cfg)\n            elif ds == \"dwd\":\n                df_out = fetch_dwd_loc(cfg)\n            elif ds == \"gddp\":\n                df_out = fetch_ee_loc(cfg)\n            elif ds == \"era5-land\":\n                df_out = fetch_ee_loc_mod(cfg)\n            else:\n                continue\n            df_all.append(df_out)\n        except Exception as e:\n            print(f\"\u26a0\ufe0f  Failed to load {ds}: {e}\")\n</pre> import os import pandas as pd import matplotlib.pyplot as plt from hydra import initialize, compose from omegaconf import OmegaConf  from utils.utils_download import (     fetch_MSWX, extract_ts_MSWX,     fetch_dwd, extract_ts_dwd,     fetch_dwd_loc, fetch_ee_loc, fetch_ee_loc_mod,     build_output_filename )   datasets = [\"mswx\", \"dwd_hyras\", \"dwd\", \"gddp\", \"era5-land\"] parameter = \"tasmax\"  overrides_base = [     f\"weather.parameter={parameter}\",     \"time_range.start_date=2014-01-01\",     \"time_range.end_date=2014-12-31\",     \"location.lat=48.1351\",     \"location.lon=11.5761\" ]  df_all = []  with initialize(config_path=\"conf\", version_base=\"1.3\"):     for ds in datasets:         print(f\"\ud83d\udd04 Processing: {ds}\")         overrides = [f\"dataset={ds}\"] + overrides_base         cfg = compose(config_name=\"config\", overrides=overrides)         # \ud83d\udcc1 Generate output filename         cfg.output.filename = build_output_filename(cfg)         output_path = os.path.join(cfg.output.out_dir, cfg.output.filename)          print(\"\ud83d\udcc1 Output file will be:\", output_path)          try:             if ds == \"mswx\":                 fetch_MSWX(cfg)                 df_out = extract_ts_MSWX(cfg)             elif ds == \"dwd_hyras\":                 fetch_dwd(cfg)                 df_out = extract_ts_dwd(cfg)             elif ds == \"dwd\":                 df_out = fetch_dwd_loc(cfg)             elif ds == \"gddp\":                 df_out = fetch_ee_loc(cfg)             elif ds == \"era5-land\":                 df_out = fetch_ee_loc_mod(cfg)             else:                 continue             df_all.append(df_out)         except Exception as e:             print(f\"\u26a0\ufe0f  Failed to load {ds}: {e}\")  <pre>\ud83d\udd04 Processing: mswx\n\u2705 All 365 files already exist locally. No download needed.\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014001.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014002.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014003.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014004.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014005.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014006.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014007.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014008.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014009.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014010.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014011.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014012.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014013.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014014.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014015.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014016.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014017.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014018.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014019.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014020.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014021.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014022.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014023.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014024.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014025.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014026.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014027.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014028.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014029.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014030.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014031.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014032.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014033.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014034.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014035.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014036.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014037.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014038.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014039.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014040.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014041.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014042.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014043.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014044.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014045.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014046.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014047.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014048.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014049.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014050.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014051.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014052.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014053.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014054.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014055.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014056.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014057.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014058.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014059.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014060.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014061.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014062.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014063.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014064.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014065.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014066.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014067.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014068.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014069.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014070.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014071.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014072.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014073.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014074.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014075.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014076.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014077.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014078.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014079.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014080.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014081.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014082.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014083.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014084.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014085.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014086.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014087.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014088.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014089.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014090.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014091.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014092.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014093.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014094.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014095.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014096.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014097.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014098.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014099.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014100.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014101.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014102.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014103.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014104.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014105.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014106.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014107.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014108.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014109.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014110.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014111.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014112.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014113.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014114.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014115.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014116.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014117.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014118.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014119.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014120.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014121.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014122.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014123.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014124.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014125.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014126.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014127.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014128.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014129.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014130.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014131.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014132.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014133.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014134.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014135.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014136.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014137.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014138.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014139.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014140.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014141.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014142.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014143.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014144.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014145.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014146.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014147.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014148.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014149.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014150.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014151.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014152.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014153.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014154.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014155.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014156.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014157.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014158.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014159.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014160.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014161.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014162.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014163.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014164.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014165.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014166.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014167.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014168.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014169.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014170.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014171.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014172.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014173.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014174.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014175.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014176.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014177.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014178.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014179.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014180.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014181.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014182.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014183.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014184.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014185.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014186.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014187.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014188.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014189.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014190.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014191.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014192.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014193.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014194.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014195.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014196.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014197.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014198.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014199.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014200.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014201.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014202.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014203.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014204.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014205.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014206.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014207.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014208.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014209.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014210.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014211.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014212.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014213.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014214.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014215.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014216.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014217.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014218.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014219.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014220.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014221.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014222.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014223.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014224.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014225.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014226.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014227.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014228.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014229.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014230.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014231.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014232.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014233.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014234.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014235.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014236.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014237.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014238.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014239.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014240.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014241.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014242.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014243.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014244.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014245.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014246.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014247.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014248.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014249.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014250.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014251.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014252.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014253.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014254.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014255.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014256.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014257.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014258.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014259.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014260.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014261.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014262.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014263.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014264.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014265.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014266.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014267.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014268.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014269.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014270.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014271.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014272.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014273.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014274.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014275.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014276.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014277.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014278.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014279.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014280.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014281.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014282.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014283.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014284.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014285.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014286.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014287.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014288.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014289.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014290.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014291.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014292.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014293.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014294.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014295.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014296.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014297.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014298.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014299.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014300.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014301.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014302.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014303.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014304.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014305.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014306.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014307.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014308.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014309.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014310.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014311.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014312.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014313.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014314.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014315.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014316.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014317.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014318.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014319.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014320.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014321.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014322.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014323.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014324.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014325.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014326.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014327.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014328.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014329.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014330.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014331.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014332.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014333.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014334.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014335.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014336.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014337.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014338.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014339.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014340.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014341.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014342.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014343.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014344.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014345.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014346.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014347.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014348.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014349.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014350.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014351.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014352.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014353.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014354.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014355.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014356.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014357.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014358.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014359.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014360.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014361.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014362.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014363.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014364.nc\n\ud83d\udcc2 Opening: ./data/mswx/tasmax/2014365.nc\n\u2705 Saved MSWX time series to: /beegfs/muduchuru/codes/python/download/data/{provider}_{parameter}_LAT{lat}_LON{lon}_{start}_{end}.csv\n\ud83d\udd04 Processing: dwd_hyras\n\u2b07\ufe0f  Checking: https://opendata.dwd.de/climate_environment/CDC/grids_germany/daily/hyras_de/air_temperature_max/tasmax_hyras_1_2014_v6-0_de.nc\n\u2714\ufe0f  Exists locally: ./data/dwd_hyras/TASMAX/tasmax_hyras_1_2014_v6-0_de.nc\n\ud83d\udcc2 Opening: ./data/dwd_hyras/TASMAX/tasmax_hyras_1_2014_v6-0_de.nc\n\ud83d\udccc Nearest grid point at (y,x)=(295,633)\n\u2705 Saved time series to: /beegfs/muduchuru/codes/python/download/data/{provider}_{parameter}_LAT{lat}_LON{lon}_{start}_{end}.csv\n\ud83d\udd04 Processing: dwd\n\u2705 Saved time series to: /beegfs/muduchuru/codes/python/download/data/{provider}_{parameter}_LAT{lat}_LON{lon}_{start}_{end}.csv\n\ud83d\udd04 Processing: gddp\n[\u2713] Saved: /beegfs/muduchuru/codes/python/download/data/{provider}_{parameter}_LAT{lat}_LON{lon}_{start}_{end}.csv\n\ud83d\udd04 Processing: era5-land\n[i] Fetching time series for point: (48.1351, 11.5761)\n</pre> <pre>Processing images: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 364/364 [09:24&lt;00:00,  1.55s/it]</pre> <pre>[\u2713] Saved timeseries to: /beegfs/muduchuru/codes/python/download/data/{provider}_{parameter}_LAT{lat}_LON{lon}_{start}_{end}.csv\n</pre> <pre>\n</pre> In\u00a0[50]: Copied! <pre>import pandas as pd\nimport pint\nimport pint_pandas\n\n# Setup\nureg = pint.UnitRegistry()\nureg.setup_matplotlib()\npint_pandas.PintType.ureg = ureg\n\n# Concatenate input\ndf = pd.concat(df_all)\n\n# Standardize units\nunit_map = {\n    \"degree_Celsius\": \"degC\",\n    \"degC\": \"degC\",\n    \"K\": \"kelvin\"\n}\ndf[\"pint_units\"] = df[\"units\"].map(unit_map)\n\n# Construct Quantity objects\nquantities = [ureg.Quantity(v, u) for v, u in zip(df[\"value\"], df[\"pint_units\"])]\n\n# Assign with index aligned\ndf[\"value\"] = pd.Series(quantities, index=df.index, dtype=\"pint[degC]\")\n\n# Convert all to degC\ndf[\"value\"] = df[\"value\"].pint.to(\"degC\")\n\n# Clean up\ndf[\"units\"] = \"degC\"\ndf.drop(columns=\"pint_units\", inplace=True)\n\n# Ensure proper datetime formatting\ndf[\"time\"] = pd.to_datetime(df[\"time\"], utc=True).dt.tz_localize(None)\n</pre> import pandas as pd import pint import pint_pandas  # Setup ureg = pint.UnitRegistry() ureg.setup_matplotlib() pint_pandas.PintType.ureg = ureg  # Concatenate input df = pd.concat(df_all)  # Standardize units unit_map = {     \"degree_Celsius\": \"degC\",     \"degC\": \"degC\",     \"K\": \"kelvin\" } df[\"pint_units\"] = df[\"units\"].map(unit_map)  # Construct Quantity objects quantities = [ureg.Quantity(v, u) for v, u in zip(df[\"value\"], df[\"pint_units\"])]  # Assign with index aligned df[\"value\"] = pd.Series(quantities, index=df.index, dtype=\"pint[degC]\")  # Convert all to degC df[\"value\"] = df[\"value\"].pint.to(\"degC\")  # Clean up df[\"units\"] = \"degC\" df.drop(columns=\"pint_units\", inplace=True)  # Ensure proper datetime formatting df[\"time\"] = pd.to_datetime(df[\"time\"], utc=True).dt.tz_localize(None)  In\u00a0[52]: Copied! <pre>df\n</pre> df Out[52]: latitude longitude time source variable value units 0 48.1351 11.5761 2014-01-01 00:00:00 MSWX air_temperature 4.0625 degC 0 48.1351 11.5761 2014-01-01 00:00:00 ERA5-LAND tasmax 5.381005859375023 degC 0 48.1351 11.5761 2014-01-01 00:00:00 GDDP tasmax 7.476525878906273 degC 0 48.1351 11.5761 2014-01-01 00:00:00 DWD tasmax 7.75 degC 0 48.1351 11.5761 2014-01-01 12:00:00 DWD_HYRAS tasmax 6.500000096857548 degC ... ... ... ... ... ... ... ... 363 48.1351 11.5761 2014-12-30 00:00:00 GDDP tasmax 8.802819824218773 degC 363 48.1351 11.5761 2014-12-30 00:00:00 ERA5-LAND tasmax -1.9494689941406023 degC 363 48.1351 11.5761 2014-12-30 12:00:00 DWD_HYRAS tasmax -1.3000000193715096 degC 364 48.1351 11.5761 2014-12-31 00:00:00 MSWX air_temperature 0.25 degC 364 48.1351 11.5761 2014-12-31 00:00:00 DWD tasmax 0.1 degC <p>1822 rows \u00d7 7 columns</p> In\u00a0[56]: Copied! <pre>df = df.sort_values(\"time\")\n\n# Plot as before\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf['temp_C'] = df['value'].pint.m\n\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df, x=\"time\", y=\"temp_C\", hue=\"source\", marker='o')\nplt.title(\"Temperature Time Series by Source\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Temperature (\u00b0C)\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n</pre> df = df.sort_values(\"time\")  # Plot as before import matplotlib.pyplot as plt import seaborn as sns  df['temp_C'] = df['value'].pint.m  plt.figure(figsize=(12, 6)) sns.lineplot(data=df, x=\"time\", y=\"temp_C\", hue=\"source\", marker='o') plt.title(\"Temperature Time Series by Source\") plt.xlabel(\"Date\") plt.ylabel(\"Temperature (\u00b0C)\") plt.grid(True) plt.tight_layout() plt.show()  In\u00a0[59]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(12, 7))\n\n# Colorful boxplot with a palette\nsns.boxplot(data=df, x=\"source\", y=\"temp_C\", palette=\"Set3\")\n\nplt.title(\"Temperature Distribution by Source\", fontsize=16)\nplt.xlabel(\"Data Source\", fontsize=20)   # bigger x-label font size\nplt.ylabel(\"Temperature (\u00b0C)\", fontsize=20)  # bigger y-label font size\nplt.grid(True, linestyle='--', alpha=0.7)\n\n# Annotate median, Q1, Q3 for each box\ngrouped = df.groupby(\"source\")[\"temp_C\"]\n\nfor i, (source, values) in enumerate(grouped):\n    q1 = values.quantile(0.25)\n    median = values.median()\n    q3 = values.quantile(0.75)\n\n    x = i  \n\n    plt.text(x, median, f\"{median:.1f}\", ha='center', va='bottom', \n             fontsize=14, fontweight='bold', color='black')\n\n    plt.text(x, q1, f\"{q1:.1f}\", ha='center', va='bottom', \n             fontsize=12, fontweight='bold', color='blue')\n\n    plt.text(x, q3, f\"{q3:.1f}\", ha='center', va='top', \n             fontsize=12, fontweight='bold', color='red')\n\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt import seaborn as sns  plt.figure(figsize=(12, 7))  # Colorful boxplot with a palette sns.boxplot(data=df, x=\"source\", y=\"temp_C\", palette=\"Set3\")  plt.title(\"Temperature Distribution by Source\", fontsize=16) plt.xlabel(\"Data Source\", fontsize=20)   # bigger x-label font size plt.ylabel(\"Temperature (\u00b0C)\", fontsize=20)  # bigger y-label font size plt.grid(True, linestyle='--', alpha=0.7)  # Annotate median, Q1, Q3 for each box grouped = df.groupby(\"source\")[\"temp_C\"]  for i, (source, values) in enumerate(grouped):     q1 = values.quantile(0.25)     median = values.median()     q3 = values.quantile(0.75)      x = i        plt.text(x, median, f\"{median:.1f}\", ha='center', va='bottom',               fontsize=14, fontweight='bold', color='black')      plt.text(x, q1, f\"{q1:.1f}\", ha='center', va='bottom',               fontsize=12, fontweight='bold', color='blue')      plt.text(x, q3, f\"{q3:.1f}\", ha='center', va='top',               fontsize=12, fontweight='bold', color='red')  plt.tight_layout() plt.show()"}]}