{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to climdata","text":"<p>This project automates the fetching and extraction of weather data from multiple sources \u2014 such as MSWX, DWD HYRAS, ERA5-Land, NASA-NEX-GDDP, and more \u2014 for a given location and time range.</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://Kaushikreddym.github.io/climdata</li> </ul>"},{"location":"#data-sources","title":"\ud83d\udce6 Data Sources","text":"<p>This project utilizes climate and weather datasets from a variety of data sources:</p> <ul> <li> <p>DWD Station Data   Retrieved using the DWD API. Provides high-resolution observational data from Germany's national meteorological service.</p> </li> <li> <p>MSWX (Multi-Source Weather)   Accessed via GloH2O's Google Drive. Combines multiple satellite and reanalysis datasets for global gridded weather variables.</p> </li> <li> <p>DWD HYRAS   Downloaded from the DWD Open Data FTP Server. Offers gridded observational data for Central Europe, useful for hydrological applications.</p> </li> <li> <p>ERA5, ERA5-Land   Accessed through the Google Earth Engine. Provides reanalysis datasets from ECMWF with high temporal and spatial resolution.</p> </li> <li> <p>NASA NEX-GDDP   Also retrieved via Earth Engine. Downscaled CMIP5/CMIP6 climate projections developed by NASA for local-scale impact assessment.</p> </li> <li> <p>CMIP6   Obtained using ESGPull from the ESGF data nodes. Includes multi-model climate simulations following various future scenarios.</p> </li> </ul> <p>It supports: \u2705 Automatic file download (e.g., from Google Drive or online servers) \u2705 Flexible configuration via <code>config.yaml</code> \u2705 Time series extraction for a user-specified latitude/longitude \u2705 Batch processing for many locations from a CSV file</p>"},{"location":"#how-to-run-and-explore-configurations","title":"\ud83d\ude80 How to Run and Explore Configurations","text":""},{"location":"#run-a-download-job-with-custom-overrides","title":"\u2705 Run a download job with custom overrides","text":"<p>You can run the data download script and override any configuration value directly in the command line using Hydra.</p> <p>For example, to download ERA5-Land data for January 1\u20134, 2020, run:</p> <pre><code>python download_location.py dataset='era5-land' \\\n  time_range.start_date='2020-01-01' \\\n  time_range.end_date='2020-01-04' \\\n  location.lat=52.5200 \\\n  location.lon=13.4050\n</code></pre> <p>For downloading multiple locations from a csv file <code>locations.csv</code>, run:</p> <pre><code>python download_csv.py dataset='era5-land' \\\n  time_range.start_date='2020-01-01' \\\n  time_range.end_date='2020-01-04' \\\n</code></pre> <p>an example <code>locations.csv</code> can be</p> <pre><code>lat,lon,city\n52.5200,13.4050,berlin\n48.1351,11.5820,munich\n53.5511,9.9937,hamburg\n</code></pre> <p>What this does:</p> <ul> <li><code>dataset='era5-land'</code> tells the script which dataset to use.</li> <li><code>time_range.start_date</code> and <code>time_range.end_date</code> override the default dates in your YAML config.</li> <li>All other settings use your existing <code>config.yaml</code> in the <code>conf</code> folder.</li> </ul>"},{"location":"#list-all-available-datasets-defined-in-your-configuration","title":"\u2705 List all available datasets defined in your configuration","text":"<p>To see what datasets are available (without running the downloader), you can dump the resolved configuration and filter it using <code>yq</code>.</p> <p>Run:</p> <pre><code>python download_location.py --cfg job | yq '.mappings | keys'\n</code></pre> <p>What this does:</p> <ul> <li><code>--cfg job</code> tells Hydra to output the final resolved configuration and exit.</li> <li><code>| yq '.mappings | keys'</code> filters the output to show only the dataset names defined under the <code>mappings</code> section.</li> </ul>"},{"location":"#tip","title":"\u26a1\ufe0f Tip","text":"<ul> <li> <p>Make sure <code>yq</code> is installed:   <pre><code>brew install yq   # macOS\n# OR\npip install yq\n</code></pre></p> </li> <li> <p>To see available variables for a specific dataset (for example <code>mswx</code>), run:   <pre><code>python download_location.py --cfg job | yq '.mappings.mswx.variables | keys'\n</code></pre></p> </li> </ul>"},{"location":"#key-features","title":"\u2699\ufe0f Key Features","text":"<ul> <li>Supports multiple weather data providers</li> <li>Uses <code>xarray</code> for robust gridded data extraction</li> <li>Handles curvilinear and rectilinear grids</li> <li>Uses a Google Drive Service Account for secure downloads</li> <li>Easily reproducible runs using Hydra</li> </ul>"},{"location":"#google-drive-api-setup","title":"\ud83d\udce1 Google Drive API Setup","text":"<p>This project uses the Google Drive API with a Service Account to securely download weather data files from a shared Google Drive folder.</p> <p>Follow these steps to set it up correctly:</p>"},{"location":"#1-create-a-google-cloud-project","title":"\u2705 1. Create a Google Cloud Project","text":"<ul> <li>Go to Google Cloud Console.</li> <li>Click \u201cSelect Project\u201d \u2192 \u201cNew Project\u201d.</li> <li>Enter a project name (e.g. <code>WeatherDataDownloader</code>).</li> <li>Click \u201cCreate\u201d.</li> </ul>"},{"location":"#2-enable-the-google-drive-api","title":"\u2705 2. Enable the Google Drive API","text":"<ul> <li>In the left sidebar, go to APIs &amp; Services \u2192 Library.</li> <li>Search for \u201cGoogle Drive API\u201d.</li> <li>Click it, then click \u201cEnable\u201d.</li> </ul>"},{"location":"#3-create-a-service-account","title":"\u2705 3. Create a Service Account","text":"<ul> <li>Go to IAM &amp; Admin \u2192 Service Accounts.</li> <li>Click \u201cCreate Service Account\u201d.</li> <li>Enter a name (e.g. <code>weather-downloader-sa</code>).</li> <li>Click \u201cCreate and Continue\u201d. You can skip assigning roles for read-only Drive access.</li> <li>Click \u201cDone\u201d to finish.</li> </ul>"},{"location":"#4-create-and-download-a-json-key","title":"\u2705 4. Create and Download a JSON Key","text":"<ul> <li>After creating the Service Account, click on its email address to open its details.</li> <li>Go to the \u201cKeys\u201d tab.</li> <li>Click \u201cAdd Key\u201d \u2192 \u201cCreate new key\u201d \u2192 choose <code>JSON</code> \u2192 click \u201cCreate\u201d.</li> <li>A <code>.json</code> key file will download automatically. Store it securely!</li> </ul>"},{"location":"#5-store-the-json-key-securely","title":"\u2705 5. Store the JSON Key Securely","text":"<ul> <li>Place the downloaded <code>.json</code> key in the conf folder with the name service.json. </li> </ul>"},{"location":"#setup-instructions-fro-era5-api","title":"Setup Instructions fro ERA5 api","text":""},{"location":"#1-cds-api-key-setup","title":"1. CDS API Key Setup","text":"<ol> <li>Create a free account on the Copernicus Climate Data Store</li> <li>Once logged in, go to your user profile</li> <li>Click on the \"Show API key\" button</li> <li>Create the file <code>~/.cdsapirc</code> with the following content:</li> </ol> <pre><code>url: https://cds.climate.copernicus.eu/api/v2\nkey: &lt;your-api-key-here&gt;\n</code></pre> <ol> <li>Make sure the file has the correct permissions: <code>chmod 600 ~/.cdsapirc</code></li> </ol>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"climdata/","title":"climdata module","text":""},{"location":"climdata/#climdata","title":"<code>climdata</code>  <code>special</code>","text":"<p>Top-level package for climdata.</p>"},{"location":"climdata/#climdata.utils","title":"<code>utils</code>  <code>special</code>","text":""},{"location":"climdata/#climdata.utils.config","title":"<code>config</code>","text":""},{"location":"climdata/#climdata.utils.config.load_config","title":"<code>load_config(config_name='config', overrides=None, verbose=False)</code>","text":"<p>Load Hydra config using ./conf in cwd.</p> Source code in <code>climdata/utils/config.py</code> <pre><code>def load_config(config_name=\"config\", overrides=None, verbose=False):\n    \"\"\"\n    Load Hydra config using ./conf in cwd.\n    \"\"\"\n    config_path = _ensure_local_conf()\n    print(config_path+config_name)\n    with initialize(config_path=config_path, version_base=None):\n        cfg = compose(config_name=config_name, overrides=overrides or [])\n        if verbose:\n            print(OmegaConf.to_yaml(cfg))\n        return cfg\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download","title":"<code>utils_download</code>","text":""},{"location":"climdata/#climdata.utils.utils_download.download_drive_file","title":"<code>download_drive_file(file_id, local_path, service)</code>","text":"<p>Download a single file from Drive to a local path.</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def download_drive_file(file_id, local_path, service):\n    \"\"\"\n    Download a single file from Drive to a local path.\n    \"\"\"\n    request = service.files().get_media(fileId=file_id)\n    os.makedirs(os.path.dirname(local_path), exist_ok=True)\n\n    with io.FileIO(local_path, 'wb') as fh:\n        downloader = MediaIoBaseDownload(fh, request)\n\n        done = False\n        while not done:\n            status, done = downloader.next_chunk()\n            print(f\"   \u2192 Download {int(status.progress() * 100)}% complete\")\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download.fetch_dwd","title":"<code>fetch_dwd(var_cfg, var)</code>","text":"<p>Download HYRAS data for one variable and a list of years.</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def fetch_dwd(var_cfg,var):\n    \"\"\"Download HYRAS data for one variable and a list of years.\"\"\"\n    param_mapping = var_cfg.dsinfo\n    provider = var_cfg.dataset.lower()\n    parameter_key = var\n    # Validate provider and parameter\n\n    param_info = param_mapping[provider]['variables'][parameter_key]\n    base_url = param_info[\"base_url\"]\n    prefix = param_info[\"prefix\"]\n    version = param_info[\"version\"]\n\n    start_date = var_cfg.time_range.start_date\n    end_date = var_cfg.time_range.end_date\n\n    # Parse dates &amp; extract unique years\n    start_year = datetime.fromisoformat(start_date).year\n    end_year = datetime.fromisoformat(end_date).year\n    years = list(range(start_year, end_year + 1))\n\n    # output_file = cfg.output.filename\n    os.makedirs(parameter_key, exist_ok=True)\n\n    for year in years:\n        file_name = f\"{prefix}_{year}_{version}_de.nc\"\n        file_url = f\"{base_url}{file_name}\"\n        local_path = os.path.join(var_cfg.data_dir,provider,parameter_key.upper(), file_name)\n        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n        print(f\"\u2b07\ufe0f  Checking: {file_url}\")\n\n        # Check if file exists on server first (HEAD request)\n        head = requests.head(file_url)\n        if head.status_code != 200:\n            raise FileNotFoundError(f\"\u274c Not found on server: {file_url} (HTTP {head.status_code})\")\n\n        if os.path.exists(local_path):\n            print(f\"\u2714\ufe0f  Exists locally: {local_path}\")\n            continue\n\n        print(f\"\u2b07\ufe0f  Downloading: {file_url}\")\n        try:\n            response = requests.get(file_url, stream=True)\n            response.raise_for_status()\n            with open(local_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n            print(f\"\u2705 Saved: {local_path}\")\n        except requests.HTTPError as e:\n            raise RuntimeError(f\"\u274c Failed download: {file_url} \u2014 {e}\")\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download.find_nearest_xy","title":"<code>find_nearest_xy(ds, target_lat, target_lon)</code>","text":"<p>Given a dataset with curvilinear grid, find the nearest x,y index.</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def find_nearest_xy(ds, target_lat, target_lon):\n    \"\"\"\n    Given a dataset with curvilinear grid, find the nearest x,y index.\n    \"\"\"\n    lat = ds['lat'].values  # shape (y,x) or (x,y)\n    lon = ds['lon'].values\n\n    # Flatten to 1D for k-d tree\n    lat_flat = lat.flatten()\n    lon_flat = lon.flatten()\n\n    tree = cKDTree(np.column_stack((lat_flat, lon_flat)))\n    _, idx = tree.query([target_lat, target_lon])\n    iy, ix = np.unravel_index(idx, lat.shape)\n\n    return iy, ix\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download.get_output_filename","title":"<code>get_output_filename(cfg, output_type='nc', lat=None, lon=None, shp_name=None, param='surface')</code>","text":"<p>Generate output filename based on config, output type, and extraction mode. output_type: \"nc\", \"csv\", or \"zarr\"</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def get_output_filename(cfg, output_type=\"nc\", lat=None, lon=None, shp_name = None, param=\"surface\"):\n    \"\"\"\n    Generate output filename based on config, output type, and extraction mode.\n    output_type: \"nc\", \"csv\", or \"zarr\"\n    \"\"\"\n    if output_type == \"csv\":\n        template = cfg.output.filename_csv\n    elif output_type == \"zarr\":\n        template = cfg.output.filename_zarr\n    else:\n        template = cfg.output.filename_nc\n\n    # If lat/lon are provided, use point template\n    if lat is not None and lon is not None:\n        filename = template.format(\n            provider=cfg.dataset,\n            parameter=param,\n            lat=f\"{lat}\",\n            lon=f\"{lon}\",\n            start=cfg.time_range.start_date.replace(\"-\", \"\"),\n            end=cfg.time_range.end_date.replace(\"-\", \"\"),\n        )\n    elif shp_name is not None:\n        filename = template.format(\n            provider=cfg.dataset,\n            parameter=param,\n            lat_range=f\"{shp_name}\",\n            lon_range=f\"{shp_name}\",\n            start=cfg.time_range.start_date.replace(\"-\", \"\"),\n            end=cfg.time_range.end_date.replace(\"-\", \"\"),\n        )\n    else:\n        # Use region bounds\n        region_bounds = cfg.bounds[cfg.region]\n        filename = template.format(\n            provider=cfg.dataset,\n            parameter=param,\n            lat_range=f\"{region_bounds['lat_min']}-{region_bounds['lat_max']}\",\n            lon_range=f\"{region_bounds['lon_min']}-{region_bounds['lon_max']}\",\n            start=cfg.time_range.start_date.replace(\"-\", \"\"),\n            end=cfg.time_range.end_date.replace(\"-\", \"\"),\n        )\n    return filename\n</code></pre>"},{"location":"climdata/#climdata.utils.utils_download.list_drive_files","title":"<code>list_drive_files(folder_id, service)</code>","text":"<p>List all files in a Google Drive folder, handling pagination.</p> Source code in <code>climdata/utils/utils_download.py</code> <pre><code>def list_drive_files(folder_id, service):\n    \"\"\"\n    List all files in a Google Drive folder, handling pagination.\n    \"\"\"\n    files = []\n    page_token = None\n\n    while True:\n        results = service.files().list(\n            q=f\"'{folder_id}' in parents and trashed = false\",\n            fields=\"files(id, name), nextPageToken\",\n            pageToken=page_token\n        ).execute()\n\n        files.extend(results.get(\"files\", []))\n        page_token = results.get(\"nextPageToken\", None)\n\n        if not page_token:\n            break\n\n    return files\n</code></pre>"},{"location":"climdata/#climdata.utils.wrapper","title":"<code>wrapper</code>","text":""},{"location":"climdata/#climdata.utils.wrapper.preprocess_aoi","title":"<code>preprocess_aoi(cfg)</code>","text":"<p>Normalize AOI in cfg: - Converts string AOI \u2192 dict - Extracts shapely geometry from FeatureCollection, Feature, or raw geometry - Detects type: point, bbox, or polygon - Updates cfg with:     cfg.aoi_type: \"point\" | \"bbox\" | \"polygon\"     cfg.lat, cfg.lon: for point     cfg.bounds: [minx, miny, maxx, maxy] for bbox/polygon     cfg.geometry: shapely geometry object</p> Source code in <code>climdata/utils/wrapper.py</code> <pre><code>def preprocess_aoi(cfg):\n    \"\"\"\n    Normalize AOI in cfg:\n    - Converts string AOI \u2192 dict\n    - Extracts shapely geometry from FeatureCollection, Feature, or raw geometry\n    - Detects type: point, bbox, or polygon\n    - Updates cfg with:\n        cfg.aoi_type: \"point\" | \"bbox\" | \"polygon\"\n        cfg.lat, cfg.lon: for point\n        cfg.bounds: [minx, miny, maxx, maxy] for bbox/polygon\n        cfg.geometry: shapely geometry object\n    \"\"\"\n    # -----------------------------\n    # 1) Load AOI value from string\n    # -----------------------------\n    if not hasattr(cfg, \"aoi\") or cfg.aoi is None:\n        return cfg\n\n    if isinstance(cfg.aoi, str):\n        try:\n            cfg.aoi = json.loads(cfg.aoi)\n        except json.JSONDecodeError:\n            raise ValueError(f\"AOI string is not valid JSON: {cfg.aoi}\")\n\n    aoi = cfg.aoi\n\n    # -----------------------------\n    # 2) Extract shapely geometry\n    # -----------------------------\n    if aoi.get(\"type\") == \"FeatureCollection\":\n        if not aoi.get(\"features\"):\n            raise ValueError(\"FeatureCollection contains no features\")\n        geom = shape(aoi[\"features\"][0][\"geometry\"])\n    elif aoi.get(\"type\") == \"Feature\":\n        geom = shape(aoi[\"geometry\"])\n    elif \"type\" in aoi and \"coordinates\" in aoi:\n        geom = shape(aoi)\n    else:\n        raise ValueError(f\"Unsupported AOI format: {aoi}\")\n    # -----------------------------\n    # 3) Determine AOI type\n    # -----------------------------\n    if isinstance(geom, Point):\n        # cfg.aoi_type = \"point\"\n        cfg.lat = geom.y\n        cfg.lon = geom.x\n        cfg.bounds = None\n    elif isinstance(geom, Polygon):\n        # Check if axis-aligned bbox\n        coords = list(geom.exterior.coords)\n        is_bbox = len(coords) == 5 and len({c[0] for c in coords}) == 2 and len({c[1] for c in coords}) == 2\n\n        # if is_bbox:\n        #     cfg.aoi_type = \"bbox\"\n        # else:\n        #     cfg.aoi_type = \"polygon\"\n\n        minx, miny, maxx, maxy = geom.bounds\n        cfg.bounds['custom'] = {\n                \"lat_min\": miny,\n                \"lat_max\": maxy,\n                \"lon_min\": minx,\n                \"lon_max\": maxx\n            }\n        cfg.region='custom'\n        cfg.lat = None\n        cfg.lon = None\n    else:\n        raise ValueError(f\"Unsupported geometry type: {geom.geom_type}\")\n\n    # -----------------------------\n    # 4) Store geometry itself\n    # -----------------------------\n    # cfg.shapefile = geom\n\n    return cfg\n</code></pre>"},{"location":"common/","title":"Common Concepts in climdata","text":"<p>This page describes common terminology, configuration patterns, and reusable components in the <code>climdata</code> package.</p>"},{"location":"common/#configuration-files","title":"Configuration Files","text":"<ul> <li>All configuration is managed via Hydra and YAML files in the <code>conf/</code> directory.</li> <li>See <code>config.yaml</code> for the main entry point.</li> </ul>"},{"location":"common/#standard-variable-names","title":"Standard Variable Names","text":"<ul> <li>Variables follow CF conventions (see <code>variables.yaml</code>).</li> <li>Example: <code>tas</code> for air temperature, <code>pr</code> for precipitation.</li> </ul>"},{"location":"common/#output-schema","title":"Output Schema","text":"<p>All outputs are standardized to the following columns:</p> Column Description latitude Latitude of observation/grid longitude Longitude of observation/grid time Timestamp source Data source/provider variable Variable name value Observed or modeled value units Units of measurement"},{"location":"common/#regions-and-bounds","title":"Regions and Bounds","text":"<ul> <li>Regions are defined in <code>config.yaml</code> under <code>bounds</code>.</li> <li>Example: <code>europe</code>, <code>global</code>.</li> </ul>"},{"location":"common/#usage-patterns","title":"Usage Patterns","text":"<ul> <li>Use <code>climdata.load_config()</code> to load configuration.</li> <li>Use <code>climdata.DWD(cfg)</code> or <code>climdata.MSWX(cfg)</code> for dataset access.</li> </ul> <p>Add more shared concepts as your documentation grows.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/Kaushikreddym/climdata/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>climdata could always use more documentation, whether as part of the official climdata docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/Kaushikreddym/climdata/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up climdata for local development.</p> <ol> <li> <p>Fork the climdata repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/climdata.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv climdata\n$ cd climdata/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 climdata tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/Kaushikreddym/climdata/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install climdata, run this command in your terminal:</p> <pre><code>pip install climdata\n</code></pre> <p>This is the preferred method to install climdata, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install climdata from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/Kaushikreddym/climdata\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use climdata in a project:</p> <pre><code>import climdata\n</code></pre>"}]}